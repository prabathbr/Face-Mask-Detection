{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2caac871",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPU Reset if needed\n",
    "\n",
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "336ed57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "base_directory = \"i:/image_classify/\" # base directory\n",
    "image_size  = (224, 224) # preprocessing image size for model input to match with input_tensor in the model\n",
    "classify_names = [\"type1_male\", \"type2_male\", \"type3_male\", \"type4_male\",\"type1_female\", \"type2_female\", \"type3_female\", \"type4_female\"] # class names to be classified into (same as sub folder names with images in different classes)\n",
    "\n",
    "# Description given in dataset link is incorrect, correct descriptions should be as below.\n",
    "classify_desc = [\"Male, mask is worn correctly, covers the nose and mouth\", \"Male, mask covers the mouth, but does not cover the nose\", \"Male, mask is on, but does not cover the nose or mouth.\", \"Male, no mask on the face\",\"Female, mask is worn correctly, covers the nose and mouth\", \"Female, mask covers the mouth, but does not cover the nose\", \"Female, mask is on, but does not cover the nose or mouth.\", \"Female, no mask on the face\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef8f04c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base directory : i:\\image_classify\n"
     ]
    }
   ],
   "source": [
    "# Change to base directory\n",
    "\n",
    "import os\n",
    "os.chdir(base_directory)\n",
    "print(\"base directory : \" + os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "075a60bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Uncomment and use suitable code block from below two code blocks depending on a local file or URL for an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ca3770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load image from local file\n",
    "\n",
    "# test_image = \"test_img.jpg\"\n",
    "\n",
    "# image_src = cv2.imread(test_image)\n",
    "# plt.imshow(image_src)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "545f1c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load image from a URL\n",
    "\n",
    "test_image = \"https://test_url\"\n",
    "\n",
    "img_from_url = requests.get(test_image)\n",
    "arr = np.asarray(bytearray(img_from_url.content), dtype = np.uint8)\n",
    "image_src = cv2.imdecode(arr, -1)\n",
    "#plt.imshow(image_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af290a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image file and preprocessing\n",
    "\n",
    "image = cv2.resize(image_src,dsize=(image_size[0],image_size[1]), interpolation = cv2.INTER_CUBIC) \n",
    "np_image_data = np.asarray(image)\n",
    "\n",
    "image = np.expand_dims(image, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efd0bcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version : 2.9.0-dev20220102\n"
     ]
    }
   ],
   "source": [
    "# Import Tensorflow and related libraries\n",
    "\n",
    "import tensorflow\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "print(\"TensorFlow version : \" + tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d7644ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: /physical_device:GPU:0   Type: GPU\n"
     ]
    }
   ],
   "source": [
    "# Display available GPUs\n",
    "\n",
    "physical_devices = tensorflow.config.list_physical_devices('GPU')\n",
    "for gpu in physical_devices:\n",
    "    print(\"Name:\", gpu.name, \"  Type:\", gpu.device_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd734343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable Memory Growth\n",
    "\n",
    "if physical_devices != []:\n",
    "    tensorflow.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    physical_devices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69fe2c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "Model: \"verification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " identify (Functional)       (None, 8)                 53477182  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 53,477,182\n",
      "Trainable params: 0\n",
      "Non-trainable params: 53,477,182\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load the saved model\n",
    "\n",
    "saved_model = load_model('identify_final.h5')\n",
    "\n",
    "# create a model with inpots and outputs to evaluate\n",
    "input_tensor = Input((224, 224, 3))\n",
    "model = Model(inputs=input_tensor, outputs=saved_model(input_tensor))\n",
    "model._name = \"verification\"\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6bdfc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preditcation array: [[6.6293523e-02 8.6844355e-01 2.7361808e-02 1.3680331e-02 4.1277823e-03\n",
      "  1.8662220e-02 9.3854347e-04 4.9225119e-04]]\n",
      "\n",
      "Preditcation index: 1\n"
     ]
    }
   ],
   "source": [
    "predict_class = model.predict(image)\n",
    "print(\"Preditcation array: \" + str(predict_class) + \"\\n\")\n",
    "\n",
    "predict_class = np.argmax(predict_class[0])\n",
    "print(\"Preditcation index: \" + str(predict_class))\n",
    "\n",
    "prediction = classify_names[predict_class]\n",
    "prediction_desc = classify_desc[predict_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a577f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type2_male\n",
      "Male, mask covers the mouth, but does not cover the nose\n"
     ]
    }
   ],
   "source": [
    "print(prediction)\n",
    "print(prediction_desc)\n",
    "#plt.imshow(image_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d0aead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa19ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (Tensorflow 2.6)",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
