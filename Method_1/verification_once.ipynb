{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "virtual-optimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPU Reset if needed\n",
    "\n",
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "orange-jacksonville",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "base_directory = \"i:/image_classify/\" # base directory\n",
    "image_directory = base_directory + \"dataset_cleaned_part7\" # image directory\n",
    "image_size  = (224, 224) # preprocessing image size for model input to match with input_tensor in the model\n",
    "classify_names = [\"type1_male\", \"type2_male\", \"type3_male\", \"type4_male\",\"type1_female\", \"type2_female\", \"type3_female\", \"type4_female\"] # class names to be classified into (same as sub folder names with images in different classes)\n",
    "\n",
    "batch_size = 25 # number of images per batch to be processed\n",
    "\n",
    "# unused paramaters\n",
    "#shuffle_value = True\n",
    "#seed_value = 1337\n",
    "#epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "centered-maria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base directory : i:\\image_classify\n"
     ]
    }
   ],
   "source": [
    "# Change to base directory\n",
    "\n",
    "import os\n",
    "os.chdir(base_directory)\n",
    "print(\"base directory : \" + os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "original-edition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version : 2.9.0-dev20220102\n"
     ]
    }
   ],
   "source": [
    "# Import Tensorflow and related libraries\n",
    "\n",
    "import tensorflow\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "print(\"TensorFlow version : \" + tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "continuing-auditor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: /physical_device:GPU:0   Type: GPU\n"
     ]
    }
   ],
   "source": [
    "# Display available GPUs\n",
    "\n",
    "physical_devices = tensorflow.config.list_physical_devices('GPU')\n",
    "for gpu in physical_devices:\n",
    "    print(\"Name:\", gpu.name, \"  Type:\", gpu.device_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "federal-struggle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable Memory Growth\n",
    "\n",
    "if physical_devices != []:\n",
    "    tensorflow.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    physical_devices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "purple-hindu",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9359 files belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create pipeline to load images\n",
    "\n",
    "val_ds = tensorflow.keras.preprocessing.image_dataset_from_directory(\n",
    "    image_directory,\n",
    "    labels='inferred', \n",
    "    label_mode='int', \n",
    "    class_names=classify_names,    \n",
    "    #validation_split=0.3,\n",
    "    #subset=\"validation\",\n",
    "    #shuffle=shuffle_value,\n",
    "    #seed=seed_value,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "val_ds = val_ds.prefetch(buffer_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acting-midwest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"verification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " classify_once (Functional)  (None, 8)                 26743688  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,743,688\n",
      "Trainable params: 12,087,304\n",
      "Non-trainable params: 14,656,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load the saved model\n",
    "\n",
    "saved_model = load_model('classify_once.h5')\n",
    "\n",
    "# create a model with inpots and outputs to evaluate\n",
    "input_tensor = Input((224, 224, 3))\n",
    "model = Model(inputs=input_tensor, outputs=saved_model(input_tensor))\n",
    "model._name = \"verification\"\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "manufactured-niagara",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tensorflow.keras.optimizers.Adam(1e-3),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "unlike-ballot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate\n",
      "375/375 [==============================] - 89s 215ms/step - loss: 0.9522 - accuracy: 0.7821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.9521716833114624, 'accuracy': 0.7821348309516907}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model with test images\n",
    "\n",
    "print(\"Evaluate\")\n",
    "result = model.evaluate(val_ds)\n",
    "dict(zip(model.metrics_names, result))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (Tensorflow 2.6)",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
